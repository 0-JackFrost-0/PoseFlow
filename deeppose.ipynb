{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeZDLK6yNeSjfziLJhRpdZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0-JackFrost-0/PoseFlow/blob/main/deeppose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a69StddDoidS"
      },
      "outputs": [],
      "source": [
        "import scipy.io as sc\n",
        "import numpy as np\n",
        "import glob\n",
        "from os.path import basename as b\n",
        "import re\n",
        "\n",
        "joints = sc.loadmat(\"FLIC_Dataset/joints.mat\")\n",
        "joints = joints['joints'].transpose(2,0,1)\n",
        "joints = joints[:, :, :2]\n",
        "\n",
        "N_test = int(len(joints)*0.1)\n",
        "perm = np.random.permutation(int(len(joints)))[:N_test].tolist()\n",
        "\n",
        "fp_train = open('train_joints.csv', 'w')\n",
        "fp_test = open('test_joints.csv', 'w')\n",
        "for img_fn in sorted(glob.glob('FLIC_Dataset/images/*.jpg')):\n",
        "    index = int(re.search('im([0-9]+)', b(img_fn)).groups()[0]) - 1\n",
        "    str_j = [str(j) if j > 0 else '-1'\n",
        "             for j in joints[index].flatten().tolist()]\n",
        "\n",
        "    out_list = [b(img_fn)]\n",
        "    out_list.extend(str_j)\n",
        "    out_str = ','.join(out_list)\n",
        "\n",
        "    if index in perm:\n",
        "        print(out_str, file=fp_test)\n",
        "    else:\n",
        "        print(out_str, file=fp_train)\n",
        "fp_train.close()\n",
        "fp_test.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import random\n",
        "import matplotlib.image as mpimg\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "PTbyBX6jo0lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(joints):\n",
        "    conv1_W = tf.Variable(tf.truncated_normal(shape=(11, 11, 3, 96)))\n",
        "    conv1_b = tf.Variable(tf.zeros(96))\n",
        "    conv1   = tf.nn.conv2d(joints, conv1_W, strides=[4, 4, 4, 4], padding='VALID') + conv1_b\n",
        "    conv1 = tf.nn.relu(conv1)\n",
        "    conv1 = tf.nn.local_response_normalization(conv1)\n",
        "    conv1 = tf.nn.max_pool(conv1, ksize=[3, 2, 2, 3], strides=[3, 2, 2, 3], padding='VALID')\n",
        "\n",
        "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 96, 256)))\n",
        "    conv2_b = tf.Variable(tf.zeros(256))\n",
        "    conv2   = tf.nn.conv2d(joints, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
        "    conv2 = tf.nn.relu(conv2)\n",
        "    conv2 = tf.nn.local_response_normalization(conv2)\n",
        "    conv2 = tf.nn.max_pool(conv2, ksize=[3, 2, 2, 3], strides=[3, 2, 2, 3], padding='VALID')\n",
        "\n",
        "    conv3_W = tf.Variable(tf.truncated_normal(shape=(3, 3, 256, 384)))\n",
        "    conv3_b = tf.Variable(tf.zeros(384))\n",
        "    conv3   = tf.nn.conv2d(joints, conv3_W, strides=[1, 1, 1, 1], padding='VALID') + conv3_b\n",
        "    conv3 = tf.nn.relu(conv3)\n",
        "\n",
        "    conv4_W = tf.Variable(tf.truncated_normal(shape=(3, 3, 384, 384)))\n",
        "    conv4_b = tf.Variable(tf.zeros(384))\n",
        "    conv4   = tf.nn.conv2d(joints, conv4_W, strides=[1, 1, 1, 1], padding='VALID') + conv4_b\n",
        "    conv4 = tf.nn.relu(conv4)\n",
        "\n",
        "    conv5_W = tf.Variable(tf.truncated_normal(shape=(3, 3, 384, 256)))\n",
        "    conv5_b = tf.Variable(tf.zeros(256))\n",
        "    conv5   = tf.nn.conv2d(joints, conv5_W, strides=[1, 1, 1, 1], padding='VALID') + conv5_b\n",
        "    conv5 = tf.nn.max_pool(conv5, ksize=[3, 2, 2, 3], strides=[3, 2, 2, 3], padding='VALID')\n",
        "    conv5 = tf.nn.relu(conv5)\n",
        "    conv5 = tf.nn.max_pool(conv5, ksize=[3, 2, 2, 3], strides=[3, 2, 2, 3], padding='VALID')\n",
        "\n",
        "    conv5_inputs = int(np.prod(conv5.shape()[1:]))\n",
        "    fc6_W = tf.Variable(tf.truncated_normal(shape=(conv5_inputs, 4096)))\n",
        "    fc6_b = tf.Variable(tf.zeros(4096))\n",
        "    fc6 = tf.matmul(joints, fc6_W) + fc6_b\n",
        "    fc6 = tf.nn.relu(fc6)\n",
        "    fc6 = tf.nn.dropout(fc6, 0.6)\n",
        "\n",
        "    fc6_inputs = int(fc6.shape()[1])\n",
        "    fc7_W = tf.Variable(tf.truncated_normal(shape=(fc6_inputs, 4096)))\n",
        "    fc7_b = tf.Variable(tf.zeros(4096))\n",
        "    fc7 = tf.matmul(fc6, fc7_W) + fc6_b\n",
        "    fc7 = tf.nn.relu(fc7)\n",
        "    fc7 = tf.nn.dropout(fc7, 0.6)\n",
        "\n",
        "    fc7_inputs = int(np.prod(fc7.shape()[1]))\n",
        "    fc8_W = tf.Variable(tf.truncated_normal(shape=(fc8_inputs, 14)))\n",
        "    fc8_b = tf.Variable(tf.zeros(14))\n",
        "    fc8 = tf.matmul(joints, fc8_W) + fc8_b\n",
        "\n",
        "    return fc8\n",
        ""
      ],
      "metadata": {
        "id": "U8MIy1Kbo4Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joints = 0\n",
        "# joints preprocessing still left\n",
        "Epoch = 100\n",
        "rate = 0.0005\n",
        "logits = model(joints)\n",
        "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
        "loss_operation = tf.reduce_mean(cross_entropy)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
        "training_operation = optimizer.minimize(loss_operation)"
      ],
      "metadata": {
        "id": "CiFZktdvo6xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "import os\n",
        "import caffe\n",
        "import numpy as np\n",
        "import cv2\n",
        "import sys\n",
        "import copy\n",
        "import random\n",
        "\n",
        "from globalvar import *\n",
        "\n",
        "STAGE1MODEL=sys.argv[1]\n",
        "\n",
        "#-----------------STAGE1--------------------#\n",
        "\n",
        "def Buildnet():\n",
        "    deploy='./models/deeppose/deeppose.prototxt'\n",
        "    caffe_model=STAGE1MODEL\n",
        "    MEAN_NPY_PATH = './models/deeppose/mean.npy'\n",
        "    os.system(\"rm -f \"+MEAN_NPY_PATH)\n",
        "\n",
        "    print \"Create mean.npy\"\n",
        "    MEAN_PROTO_PATH = './models/deeppose/train_mean.binaryproto'\n",
        "    blob = caffe.proto.caffe_pb2.BlobProto()\n",
        "    data = open(MEAN_PROTO_PATH, 'rb' ).read()\n",
        "    blob.ParseFromString(data)\n",
        "    array = np.array(caffe.io.blobproto_to_array(blob))\n",
        "    mean_npy = array[0]\n",
        "    np.save(MEAN_NPY_PATH ,mean_npy)\n",
        "\n",
        "    net = caffe.Net(deploy,caffe_model,caffe.TEST)\n",
        "    transformer = caffe.io.Transformer({'data':net.blobs['data'].data.shape})\n",
        "    transformer.set_mean('data', (np.load(MEAN_NPY_PATH).mean(1).mean(1))/255.)\n",
        "    transformer.set_transpose('data', (2,0,1))\n",
        "    transformer.set_channel_swap('data', (2,1,0))\n",
        "    #transformer.set_raw_scale('data', 255.0)\n",
        "    #net.blobs['data'].reshape(1,3,227,227)\n",
        "    return net,transformer\n",
        "\n",
        "def Test(img,net,transformer):\n",
        "    im = caffe.io.load_image(img)\n",
        "    net.blobs['data'].data[...] = transformer.preprocess('data', im)\n",
        "    out = copy.deepcopy(net.forward())\n",
        "    # out = net.forward_all(data=np.asarray([transformer.preprocess('data', im)]))\n",
        "    return out['predict']\n",
        "\n",
        "def process(predict,cols,rows):\n",
        "    predict=predict.reshape((JOINTS,2))\n",
        "    predict[:,0]+=0.5*cols\n",
        "    predict[:,1]+=0.5*rows\n",
        "    return predict\n",
        "\n",
        "net,trans=Buildnet()\n",
        "\n",
        "#---------------Read test set---------------#\n",
        "\n",
        "testlist=\"./models/deeppose/test_images.txt\"\n",
        "\n",
        "predict=[]\n",
        "label=[]\n",
        "total_test=0\n",
        "\n",
        "RATE=40\n",
        "\n",
        "with open(testlist,'r') as f:\n",
        "    for line in f.readlines():\n",
        "        if random.randint(1,RATE)!=1:\n",
        "            continue\n",
        "        dat=(line.lstrip('\\x00')).split()\n",
        "        img=dat[0]\n",
        "        label.append(np.zeros((JOINTS,2)))\n",
        "        for i in range(0,JOINTS*2):\n",
        "            label[-1][(i>>1),(i&1)]=eval(dat[i+1])\n",
        "        label[-1]=process(label[-1],SIZE[0],SIZE[1])\n",
        "        output=process(Test(img,net,trans),SIZE[0],SIZE[1])\n",
        "        predict.append(output)\n",
        "        total_test+=1\n",
        "        if total_test%100==0:\n",
        "            print \"Read and Predict %d Images !\"%total_test\n",
        "    if total_test%100!=0:\n",
        "        print \"Read and Predict %d Images !\"%total_test\n",
        "\n",
        "predict=np.array(predict)\n",
        "label=np.array(label)\n",
        "\n",
        "#--------------------Accuracy----------------#\n",
        "\n",
        "def dist(a,b):\n",
        "    return np.sqrt(np.sum((a-b)**2))\n",
        "\n",
        "def Diam(idx):\n",
        "    return dist(label[idx,DIAM1],label[idx,DIAM2])\n",
        "\n",
        "def PCPforOne(idx):\n",
        "    detected=0;total=0\n",
        "    lambd=0.5;\n",
        "    for i in range(0,len(LIMBS)):\n",
        "        x=LIMBS[i][0];y=LIMBS[i][1]\n",
        "        leng=dist(label[idx,x],label[idx,y])\n",
        "        total+=1;\n",
        "        if dist(predict[idx,x],label[idx,x])<=leng*lambd and dist(predict[idx,y],label[idx,y])<=leng*lambd:\n",
        "            detected+=1;\n",
        "    return detected,total\n",
        "\n",
        "\n",
        "\n",
        "def PDJforOne(idx,lambd):\n",
        "    detected=0;total=0\n",
        "    diam=Diam(idx);\n",
        "    for i in range(0,JOINTS):\n",
        "        total+=1\n",
        "        if dist(label[idx,i],predict[idx,i])<=diam*lambd:\n",
        "            detected+=1;\n",
        "    return detected,total\n",
        "\n",
        "\n",
        "\n",
        "def LossforOne(idx):\n",
        "    ret=0\n",
        "    for i in range(0,JOINTS):\n",
        "        ret+=(dist(label[idx,i],predict[idx,i]))**2;\n",
        "    return ret\n",
        "\n",
        "\n",
        "\n",
        "def PCP():\n",
        "    detected=0;total=0\n",
        "    for i in range(0,total_test):\n",
        "        ret1,ret2=PCPforOne(i)\n",
        "        detected+=ret1\n",
        "        total+=ret2\n",
        "    return float(detected)/total\n",
        "\n",
        "\n",
        "\n",
        "def PDJ(lambd):\n",
        "    detected=0;total=0\n",
        "    for i in range(0,total_test):\n",
        "        ret1,ret2=PDJforOne(i,lambd)\n",
        "        detected+=ret1\n",
        "        total+=ret2\n",
        "    return float(detected)/total;\n",
        "\n",
        "\n",
        "def Loss():\n",
        "    ret=0;\n",
        "    for i in range(0,total_test):\n",
        "        ret+=LossforOne(i)\n",
        "    return ret/2.0/total_test/(JOINTS*2.0)\n",
        "\n",
        "print \"Loss: \",Loss()\n",
        "print \"PCP: \",PCP()\n",
        "for i in range(5,80,5):\n",
        "    lambd=i/100.0\n",
        "    print \"PDJ for norm %.2lf\"%lambd,\": %.6lf\"%PDJ(lambd)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "hIJ48rcgo9yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6EmArQEMpQPx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}